{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting on new data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# As usual we are starting a new notebook and we need to import all relevant packages\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# To load the scaler we use the pickle method load\r\n",
    "scaler_deep_learning = pickle.load(open('scaler_deep_learning.pickle', 'rb'))\r\n",
    "# To load the model, we use the TensorFlow (Keras) function relevant for the operation\r\n",
    "model = tf.keras.models.load_model('audiobooks_model.h5')\r\n",
    "\r\n",
    "# Note that since we did not specify the input shape of our inputs in the modeling part, we get a warning\r\n",
    "# For feed-forward neural networks such as ours that is not an issue"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the new data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# The new data is located in 'New_Audiobooks_Data.csv'\r\n",
    "# To keep everything as before, we must specify the delimiter explicitly\r\n",
    "raw_data = np.loadtxt('New_Audiobooks_Data.csv',delimiter=',')\r\n",
    "# We are interested in all data except for the first column (ID)\r\n",
    "# Note that there are no targets in this CSV file (we don't know the behavior of these clients, yet!)\r\n",
    "new_data_inputs = raw_data[:,1:]\r\n",
    "# new_data_inputs = np.reshape([1188,5.33,0,8.91,0.12,0,0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "new_data_inputs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.1880e+03, 1.1880e+03, 5.3300e+00, 5.3300e+00, 0.0000e+00,\n",
       "        8.9100e+00, 1.2000e-01, 0.0000e+00, 0.0000e+00, 3.9000e+01],\n",
       "       [6.4800e+02, 6.4800e+02, 5.3300e+00, 5.3300e+00, 0.0000e+00,\n",
       "        8.9100e+00, 4.8000e-01, 0.0000e+00, 0.0000e+00, 9.1000e+01],\n",
       "       [2.1600e+03, 2.1600e+03, 7.6900e+00, 7.6900e+00, 0.0000e+00,\n",
       "        8.9100e+00, 0.0000e+00, 6.8040e+02, 0.0000e+00, 0.0000e+00],\n",
       "       [1.6740e+03, 3.3480e+03, 8.0000e+00, 1.6000e+01, 1.0000e+00,\n",
       "        1.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7000e+01],\n",
       "       [2.1600e+03, 2.1600e+03, 5.6600e+00, 5.6600e+00, 0.0000e+00,\n",
       "        8.9100e+00, 1.2000e-01, 7.3440e+02, 0.0000e+00, 1.9800e+02],\n",
       "       [2.1600e+03, 2.1600e+03, 6.5800e+00, 6.5800e+00, 0.0000e+00,\n",
       "        8.9100e+00, 0.0000e+00, 7.3440e+02, 0.0000e+00, 0.0000e+00],\n",
       "       [2.1600e+03, 2.1600e+03, 5.3300e+00, 5.3300e+00, 0.0000e+00,\n",
       "        8.9100e+00, 0.0000e+00, 6.8040e+02, 0.0000e+00, 0.0000e+00],\n",
       "       [2.1600e+03, 2.1600e+03, 7.9300e+00, 7.9300e+00, 0.0000e+00,\n",
       "        8.9100e+00, 3.0000e-02, 6.8040e+02, 0.0000e+00, 1.5200e+02],\n",
       "       [2.1600e+03, 2.1600e+03, 4.0900e+00, 4.0900e+00, 0.0000e+00,\n",
       "        8.9100e+00, 0.0000e+00, 6.8040e+02, 0.0000e+00, 0.0000e+00],\n",
       "       [2.1600e+03, 2.1600e+03, 5.6100e+00, 5.6100e+00, 0.0000e+00,\n",
       "        8.9100e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1000e+01],\n",
       "       [2.1600e+03, 2.1600e+03, 1.0130e+01, 1.0130e+01, 1.0000e+00,\n",
       "        1.0000e+01, 3.4000e-01, 1.1664e+03, 0.0000e+00, 1.5000e+01],\n",
       "       [1.6200e+03, 1.6200e+03, 5.3300e+00, 5.3300e+00, 0.0000e+00,\n",
       "        8.9100e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "       [1.6200e+03, 1.6200e+03, 5.3300e+00, 5.3300e+00, 1.0000e+00,\n",
       "        6.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0000e+00],\n",
       "       [1.6200e+03, 1.6200e+03, 5.3300e+00, 5.3300e+00, 0.0000e+00,\n",
       "        8.9100e+00, 2.9000e-01, 1.1880e+03, 0.0000e+00, 2.7000e+01],\n",
       "       [6.4800e+02, 6.4800e+02, 5.3300e+00, 5.3300e+00, 0.0000e+00,\n",
       "        8.9100e+00, 0.0000e+00, 6.9660e+02, 0.0000e+00, 0.0000e+00],\n",
       "       [1.1880e+03, 1.1880e+03, 7.6800e+00, 7.6800e+00, 0.0000e+00,\n",
       "        8.9100e+00, 0.0000e+00, 6.9660e+02, 0.0000e+00, 0.0000e+00],\n",
       "       [1.1880e+03, 1.1880e+03, 8.4800e+00, 8.4800e+00, 0.0000e+00,\n",
       "        8.9100e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2000e+01],\n",
       "       [2.1600e+03, 2.1600e+03, 5.3300e+00, 5.3300e+00, 0.0000e+00,\n",
       "        8.9100e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+00],\n",
       "       [1.1880e+03, 1.1880e+03, 5.6900e+00, 5.6900e+00, 0.0000e+00,\n",
       "        8.9100e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
       "       [1.6200e+03, 1.6200e+03, 5.6100e+00, 5.6100e+00, 0.0000e+00,\n",
       "        1.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00],\n",
       "       [1.2420e+03, 2.4840e+03, 1.6800e+01, 3.3590e+01, 1.0000e+00,\n",
       "        1.0000e+01, 0.0000e+00, 6.8040e+02, 0.0000e+00, 0.0000e+00],\n",
       "       [7.5600e+02, 1.5120e+03, 5.3300e+00, 1.0670e+01, 0.0000e+00,\n",
       "        8.9100e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.1880e+03, 1.1880e+03, 1.0400e+02, 1.0400e+02, 0.0000e+00,\n",
       "        1.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.6200e+03, 1.6200e+03, 8.0000e+00, 8.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 3.5000e-01, 0.0000e+00, 0.0000e+00, 1.2000e+01],\n",
       "       [1.1880e+03, 1.1880e+03, 5.3300e+00, 5.3300e+00, 0.0000e+00,\n",
       "        8.9100e+00, 1.8000e-01, 1.4256e+02, 0.0000e+00, 4.0000e+00],\n",
       "       [1.1880e+03, 1.1880e+03, 5.3300e+00, 5.3300e+00, 0.0000e+00,\n",
       "        3.0000e+00, 0.0000e+00, 6.4800e+01, 0.0000e+00, 3.2100e+02],\n",
       "       [2.1600e+03, 2.1600e+03, 5.3300e+00, 5.3300e+00, 0.0000e+00,\n",
       "        8.9100e+00, 2.0000e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.6200e+03, 1.6200e+03, 2.4160e+01, 2.4160e+01, 1.0000e+00,\n",
       "        1.0000e+01, 4.0000e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.1340e+03, 2.2680e+03, 1.0130e+01, 2.0270e+01, 1.0000e+00,\n",
       "        1.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0200e+02],\n",
       "       [1.4760e+03, 4.4280e+03, 6.9300e+00, 2.0800e+01, 0.0000e+00,\n",
       "        9.0000e+00, 0.0000e+00, 1.7280e+02, 0.0000e+00, 2.8200e+02]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predict the probability of a customer to convert"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Scale the new data in the same way we scaled the train data\r\n",
    "new_data_inputs_scaled = scaler_deep_learning.transform(new_data_inputs)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Predict the probability of each customer to convert\r\n",
    "# Here we have also taken only the second column and rounded to 2 digits after the dot\r\n",
    "model.predict(new_data_inputs_scaled)[:,1].round(2)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.02, 0.  , 0.06, 1.  , 0.  , 0.04, 0.04, 0.04, 0.03, 0.78, 0.  ,\n",
       "       0.85, 0.96, 0.  , 0.13, 0.16, 0.91, 0.75, 0.9 , 0.97, 1.  , 1.  ,\n",
       "       1.  , 0.  , 0.  , 1.  , 0.58, 0.  , 1.  , 1.  ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Implement the better approach which is independent of the number of classes\r\n",
    "np.argmax(model.predict(new_data_inputs_scaled),1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# model.predict([1188,1188,5.33,5.33,0,8.91,0.12,0,0,39])\r\n",
    "# model.predict(np.reshape([1188,1188,5.33,5.33,0,8.91,0.12,0,0,39], (1,-1)))\r\n",
    "scaled = scaler_deep_learning.transform(np.reshape([1674,3348,8,16,1,10,0,0,0,27], (1,-1)))\r\n",
    "# np.argmax(model.predict(np.reshape([1188,1188,5.33,5.33,0,8.91,0.12,0,0,39], (1,-1))),1)\r\n",
    "pred =np.argmax(model.predict(scaled),1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "float(pred)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('hashanalytics': conda)"
  },
  "interpreter": {
   "hash": "fda10c17a9df46d77c0ae753b4e3a2aa8c45f7d9584953950091d4d531a44370"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}